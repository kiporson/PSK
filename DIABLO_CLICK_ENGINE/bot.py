#!/usr/bin/env python3
import os
import time
import requests
from scraper import scrape_proxies
from validator import validate_all
from banner import show_banner
from clicker import click_links

def check_resources():
    for filename in ['proxies_raw.txt', 'proxies_valid.txt', 'log.txt', 'useragents.txt']:
        open(filename, 'a').close()
    os.makedirs('links', exist_ok=True)

def remove_duplicate_proxies():
    seen = set()
    proxies = []
    with open("proxies_valid.txt") as f:
        for line in f:
            proxy = line.strip()
            if proxy and proxy not in seen:
                seen.add(proxy)
                proxies.append(proxy)
    with open("proxies_valid.txt", "w") as f:
        for proxy in proxies:
            f.write(proxy + '\n')
    print(f"âœ… Duplikat dihapus. Total unik: {len(proxies)} proxy.")

def count_file_lines(path):
    try:
        with open(path) as f:
            return len([line for line in f if line.strip()])
    except FileNotFoundError:
        return 0

def input_links():
    print("ğŸ”— Masukkan link shortlink satu per satu (DONE untuk selesai):")
    count = 1
    while True:
        try:
            link = input(f"Kirim link {count}: ").strip()
        except KeyboardInterrupt:
            print("\nâ›” Dibatalkan oleh pengguna.")
            break
        if link.upper() == 'DONE':
            break
        if link:
            domain = link.split('/')[2] if '://' in link else link.split('/')[0]
            path = os.path.join('links', f'{domain}.txt')
            with open(path, 'a') as f:
                f.write(link + '\n')
            count += 1
    print("âœ… Link berhasil disimpan.")

def start_bot():
    all_links = []
    for file in os.listdir("links"):
        with open(os.path.join("links", file)) as f:
            all_links.extend([l.strip() for l in f if l.strip()])
    if all_links:
        print(f"ğŸš€ Menjalankan bot pada {len(all_links)} link...")
        click_links(all_links)
    else:
        print("âŒ Tidak ada link ditemukan di folder /links")

def show_summary():
    total_raw = count_file_lines('proxies_raw.txt')
    total_valid = count_file_lines('proxies_valid.txt')
    try:
        ip = requests.get('https://api.ipify.org', timeout=5).text.strip()
    except:
        ip = "Tidak terdeteksi"
    duration = 0
    show_banner(total_valid, total_raw, ip, duration)

def menu():
    check_resources()
    while True:
        print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚        ğŸ”§ PSK ENGINE        â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print("â”‚ 1. Scrape Proxy            â”‚")
        print("â”‚ 2. Cek Duplikat Proxy      â”‚")
        print("â”‚ 3. Validasi Proxy          â”‚")
        print("â”‚ 4. Masukkan Link Shortlink â”‚")
        print("â”‚ 5. Mulai Klik Bot          â”‚")
        print("â”‚ 6. Tampilkan Ringkasan     â”‚")
        print("â”‚ 0. Keluar                  â”‚")
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        choice = input("Pilih menu: ").strip()
        
        if choice == '1':
            print("ğŸ” Scraping proxy...")
            scrape_proxies()
            print("âœ… Scraping selesai.")
        elif choice == '2':
            remove_duplicate_proxies()
        elif choice == '3':
            print("ğŸ§ª Validasi proxy...")
            validate_all()
            print("âœ… Validasi selesai.")
        elif choice == '4':
            input_links()
        elif choice == '5':
            start_bot()
        elif choice == '6':
            show_summary()
        elif choice == '0':
            print("ğŸ‘‹ Keluar.")
            break
        else:
            print("âŒ Pilihan tidak valid.")

if __name__ == '__main__':
    menu()